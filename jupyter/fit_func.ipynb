{
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "9f8fd71b98b163a0965b3204c263be7b56efe89ac907df8b2c30eb28f29cbfb8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Simple example for performing symbolic regression for a set of points"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nesymres.architectures.model import Model\n",
    "from nesymres.utils import load_metadata_hdf5\n",
    "from nesymres.dclasses import FitParams, NNEquation, BFGSParams\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import torch\n",
    "from sympy import lambdify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up BFGS load rom the hydra config yaml\n",
    "bfgs = BFGSParams(\n",
    "        activated= cfg.inference.bfgs.activated,\n",
    "        n_restarts=cfg.inference.bfgs.n_restarts,\n",
    "        add_coefficients_if_not_existing=cfg.inference.bfgs.add_coefficients_if_not_existing,\n",
    "        normalization_o=cfg.inference.bfgs.normalization_o,\n",
    "        idx_remove=cfg.inference.bfgs.idx_remove,\n",
    "        normalization_type=cfg.inference.bfgs.normalization_type,\n",
    "        stop_time=cfg.inference.bfgs.stop_time,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use same set of configuration parameters of ours test set\n",
    "import omegaconf\n",
    "test_data = load_metadata_hdf5(\"../data/validation\")\n",
    "cfg = omegaconf.OmegaConf.load(\"../scripts/config.yaml\")\n",
    "\n",
    "params_fit = FitParams(word2id=test_data.word2id, \n",
    "                            id2word=test_data.id2word, \n",
    "                            una_ops=test_data.una_ops, \n",
    "                            bin_ops=test_data.bin_ops, \n",
    "                            total_variables=list(test_data.total_variables),  \n",
    "                            total_coefficients=list(test_data.total_coefficients),\n",
    "                            rewrite_functions=list(test_data.rewrite_functions),\n",
    "                            bfgs=bfgs,\n",
    "                            beam_size=cfg.inference.beam_size #This parameter is a tradeoff between accuracy and fitting time\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"../weights/100M.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load architecture, set into eval mode, and pass the config parameters\n",
    "model = Model.load_from_checkpoint(weights_path, cfg=cfg.architecture)\n",
    "model.eval()\n",
    "if torch.cuda.is_available(): \n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitfunc = partial(model.fitfunc,cfg_params=params_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create points from an equation\n",
    "number_of_points = 500\n",
    "n_variables = 1\n",
    "\n",
    "#To get best results make sure that your support inside the max and mix support\n",
    "max_supp = cfg.dataset_train.fun_support[\"max\"] \n",
    "min_supp = cfg.dataset_train.fun_support[\"min\"]\n",
    "X = torch.rand(number_of_points,len(list(test_data.total_variables)))*(max_supp-min_supp)+min_supp\n",
    "X[:,n_variables:] = 0\n",
    "target_eq = \"x_1*sin(x_1)\" #Use x_1,x_2 and x_3 as indepdent variables\n",
    "X_dict = {x:X[:,idx].cpu() for idx, x in enumerate(test_data.total_variables)} #CHECK ME\n",
    "y = lambdify(\",\".join(test_data.total_variables), target_eq)(**X_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:  torch.Size([500, 3])\ny shape:  torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "print(\"y shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/gem/repos/NeuralSymbolicRegressionThatScales/src/nesymres/architectures/model.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X,device=self.device).unsqueeze(0)\n",
      "/home/gem/repos/NeuralSymbolicRegressionThatScales/src/nesymres/architectures/model.py:140: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y,device=self.device).unsqueeze(0)\n",
      "Memory footprint of the encoder: 6.144e-05GB \n",
      "\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n",
      "Constructing BFGS loss...\n",
      "Flag idx remove ON, Removing indeces with high values...\n",
      "checking input values range...\n",
      "Loss constructed, starting new BFGS optmization...\n"
     ]
    }
   ],
   "source": [
    "output = fitfunc(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'all_bfgs_preds': ['((x_1)*(sin(x_1)))',\n",
       "  '((x_1)*((cos(x_1))*(tan(x_1))))',\n",
       "  '1.00000001222406*x_1*sin(x_1)'],\n",
       " 'all_bfgs_loss': [0.0, 6.091805e-14, 0.0],\n",
       " 'best_bfgs_preds': ['((x_1)*(sin(x_1)))'],\n",
       " 'best_bfgs_loss': [0.0]}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}